",v
,V
" ----------------------------------------------------------------------------" Vundle" ----------------------------------------------------------------------------set nocompatible              " be iMproved, requiredfiletype off                  " required" set the runtime path to include Vundle and initializeset rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()" alternatively, pass a path where Vundle should install plugins"call vundle#begin('~/some/path/here')" let Vundle manage Vundle, requiredPlugin 'gmarik/Vundle.vim'" The following are examples of different formats supported." Keep Plugin commands between vundle#begin/end." plugin on GitHub repoPlugin 'tpope/vim-fugitive'" plugin from http://vim-scripts.org/vim/scripts.htmlPlugin 'L9'" Git plugin not hosted on GitHubPlugin 'git://git.wincent.com/command-t.git'" git repos on your local machine (i.e. when working on your own plugin)Plugin 'file:///home/gmarik/path/to/plugin'" The sparkup vim script is in a subdirectory of this repo called vim." Pass the path to set the runtimepath properly.Plugin 'rstacruz/sparkup', {'rtp': 'vim/'}" Avoid a name conflict with L9Plugin 'user/L9', {'name': 'newL9'}" All of your Plugins must be added before the following linecall vundle#end()            " requiredfiletype plugin indent on    " required" To ignore plugin indent changes, instead use:"filetype plugin on"" Brief help" :PluginList          - list configured plugins" :PluginInstall(!)    - install (update) plugins" :PluginSearch(!) foo - search (or refresh cache first) for foo" :PluginClean(!)      - confirm (or auto-approve) removal of unused plugins"" see :h vundle for more details or wiki for FAQ" Put your non-Plugin stuff after this line,v
######,1
#,v
8,v
 ,v
\,v
set guioptions-=mset guioptions-=Tset guioptions-=rset guioptions-=Lset guifont=Monospace\ 8,V
    set guioptions-=T    set guioptions-=e    set t_Co=256    set guitablabel=%M\ %t,V
if has("gui_running")    set guioptions-=T    set guioptions-=e    set t_Co=256    set guitablabel=%M\ %tendif,V
    set guifont=Monospace\ m 8,V
(1) First of all, I noticed that B1E and B1 are switched in perseus_av_cores_map.png.Please make sure that regions in Perseus are B5 - IC348 - B1E - B1 - NGC1333, from east to west (Figure 1 of Lee+12).(2) phi_CNM for B5 in perseus_rh2_vs_hsd_lee12_planck_reproduce.png looks too small compared to Lee+12.Could you please make sure that your phi_CNM is really consistent with Lee+12 within uncertainties?(3) We thought that the box orientation should follow the steepest gradient in Av.-----> I am not so sure if this selection criterion can be well justified.For example, there is some theoretical expectation for a density radial profile (n ~ r^-2) for a self-gravitating, isothermal sphere in hydrostatic equilibrium ("Bonner-Ebert sphere").Although it is not straightforward to convert the observed column density into the density, previous observations have indicated that molecular cores indeed follow this expected radial profile.See Alves et al. (2001) for B68 as an example.-----> However, I do not think that assuming the shape of Av radial profile based on theory to select box orientation is a good one.It would be best to depend on observations only.Actually, I found an interesting reference - Have you seen this?http://adsabs.harvard.edu.ezproxy.library.wisc.edu/abs/2010ApJ...725.1327SThe authors identified cores in L1495 (one of the filaments in Taurus) using Clumpfind2D (basically, two-dimensional thresholding algorithm).They then found core orientations based on the zeroth, first, and second moments.As they mainly focused on small-scale cores, their methodology may not be directly applicable for us.However, using moments to define orientation sounds interesting, and may be useful for us.Have you seen other references using moments?This paper does not provide details how to use moments, we could ask Jounie, who is the 2nd author?(4) I really like your non-parametric approach for estimating N(HI) errors.However, I should admit that I am lost after "I then used the marginal distribution of correlation coefficients for each parameter...".Basically, I think that correlation.png clearly shows that the HI central velocity is relatively well-constrained, while the HI velocity width is not.This is not surprising considering that most of the HI emission in Perseus is contained between 0 km/sec and 15 km/sec, and there is not so much beyond 20 km/sec.So correlation.png actually suggests that the observed uniform HI column density across Perseus is robust against the chosen HI velocity width.Regarding N(HI) errors:As I don't understand exactly how you estimated, I cannot comment on perseus_NGC1333_PDF_hist.png.However, here is my thought.Basically, you can use correlation.png to estimate N(HI) errors.As you considered the measured correlation coefficient as a number count, correlation.png is simply 2D likelihood distribution.In this case, the peak of the distribution ("maximum likelihood") corresponds to the best-fit parameters.In addition, the uncertainty in each parameter can be determined by finding parameter values where the maximum likelihood drops by sqrt(e).The determined uncertainty in each parameter can then be incorporated into a Monte Carlo simulation to estimate final errors in N(HI).I haven't done this kind of calculation by myself, but am pretty sure there are good references.One of the good references is:http://adsabs.harvard.edu/abs/1996QJRAS..37..519WPlease let me know if you have any questions regarding my comments.And Snez, I will get back to your comments early next week - I will be leaving for Seoul tomorrow for my nephew's 1st birthday. :),V
E,v
             #'B4':             #   {'center_wcs': [(3, 44, 18), (32, 05, 20)],             #    'map': None,             #    'threshold': None,             #    'box_wcs': None,             #    },,v
dust gas correlation variation molecular cloud,v
0,v
\label{fig:pdfs},v
_,v
    A non-parametric approach to determining the error on the HI velocity range    given that the N(HI) is non-linearly dependent on the HI velocity range. ,v
http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_discrete.html,v
n,v
r,v
    #vel_error = cores[core]['hi_velocity_range_error'],v
    print(nhi_error),v
    nhi_error = np.median(results_dict['nhi errors']),v
,},v
        mask = myg.get_polygon_mask(av_data_planck_orig,                cores[core]['box_vertices_rotated']),v
e,v
            print hi_vel_range_noise,v
+,v
            hi_vel_range_list.append(hi_vel_range),v
,v
),v
np.asarray(hi_vel_range),v
    vel_error = cores[core]['hi_velocity_range_error'],v
    for figure_type in figure_types:        if hi_co_width or hi_av_correlation:            plot_co_spectrum_grid(co_vel_axis,                    co_image_list,                    vel_range_list=hi_vel_range_list,                    vel_range_hiav_list=hi_vel_range_corr_list,                    #limits = [0, 80, 10**-3, 10**2],                    savedir = figure_dir + 'panel_cores/',                    scale = ('linear', 'linear'),                    filename = 'perseus_core_co_spectra_grid.%s' % figure_type,                    title = r'Average $^{12}$CO spectra of perseus Cores',                    core_names=core_name_list,                    show = False),v
    co_width_scale = 5.0 # for determining N(HI) vel range    # 0.758 is fraction of area of Gaussian between FWHM limits    co_flux_fraction = 0.758 # fraction of flux of average CO spectrum    hi_vel_range_scale = 1.0 # scale hi velocity range for Av/N(HI) correlation,v
    reproduce_lee12 = True,v
    cores[core]['hi_velocity_range'],v
2,v
Elijah - when doing bootstrapping please check how many iterations should be done so that you are not oversampling the parameter distribution. I also need some more explanation here re exactly what's being done (e.g. difference btw bootstrapping and Monte Carlo - do you use both methods here or just one?).,v
Orientation,v
        # Annotations        anno_xpos = 0.95,v
        if phi_cnm_list is not None:            phi_cnm = phi_cnm_list[i]        if phi_cnm_error_list is not None:            phi_cnm_error = phi_cnm_error_list[i]        if Z_list is not None:            Z = Z_list[i]        if Z_error_list is not None:            Z_error = Z_error_list[i]        if chisq_list is not None:            chisq = chisq_list[i]        if p_value_list is not None:            p_value = p_value_list[i],v
fit=True, ,v
,        phi_cnm_list=None, phi_cnm_error_list=None, Z_list=None,        Z_error_list=None, chisq_list=None, p_value_list=None,,v
$\Sigma_{HI}$ + $\Sigma_{H2}$ (M$_\odot$ / pc$^2$),v
h,v
'perseus_NGC1333_phi_cnm_hist.png',v
http://www.prepressure.com/postscript/troubleshooting/errors/image,v
B,v
3,v
        plt.show(),v
m,v
http://xkcd.com/,v
pl.hist(data, bins=np.logspace(0.1, 1.0, 50))pl.gca().set_xscale("log"),v
1,v
5,v
phi_cnm,v
g,v
b,v
        ax.plot(width_correlations_recreate, 100, alpha=0.3,                label='Widths Reproduced', color='b', normed=True),v
             label='Reproduced', color='b', normed=True),v
$\phi_{\rm CNM}$,v
t,v
    #plt.hist(center_correlations)    #plt.plot(width_correlations)    #plt.plot(center_correlations)    #plt.show(),v
x,v
(,v
    plt.hist(results_dict['phi_cnm fits'])    plt.save(),v
        if verbose:            print('HI velocity integration range:')            print('%.0f to %.0f km/s' % (hi_vel_range[0], hi_vel_range[1])),v
# # # # ,v
          ,v
# Bootstrapping using means,v
    phi_cnm = phi_cnm,v
    hi_vel_range_sample = (np.median(hi_vel_range_list[:, 0]),                           np.median(hi_vel_range_list[:, 1])),v
hi_vel_range_sample, ,v
hi_vel_range, ,v
np.median(hi_vel_range_list[:, 0]),                                        np.median(hi_vel_range_list[:, 1])),v
np.median(hi_vel_range_list[:, 0]),                                        np.median(hi_vel_range_list[:, 1]),v
    import matplotlib.pyplot as plt,v
    import mystats,v
    import random,v
    #center_corrs = [],v
    #raise ValueError('done'),v
            #vel_center_random = center_pdf(random_center_sample)            #vel_width_random = width_pdf(random_width_sample),v
pdf(random_width_sample),v
    	print(center_rv.rvs()),v
    #    center = random.uniform(vel_centers[0], vel_centers[-1] )    #    center_correlations_recreate[i] = center_pdf(center)    #for i in range(len(center_correlations_recreate)):    #    center = random.uniform(center_correlations.min(),    #                            center_correlations.max())    #    print center    #    center_correlations_recreate[i] = center_pdf(center)    #for vel_center in vel_centers:    #    center_corrs.append(center_pdf(vel_center))    # plot both    #plt.plot(vel_centers, center_correlations, label='Observed', color='r'),v
.min().max(),v
b = numpy.zeros(10000)for i in range(len( b )):    u = random.uniform( x[0], x[-1] )    b[i] = inverse_density_function( u )# plot both        pyplot.hist(a, 100) pyplot.hist(b, 100)pyplot.show(),v
http://voxcharta.org/,v
            print(hi_vel_range_noise),v
hi_vel_range_list[:, 0],v
[:, 0],v
],v
np.toarray(hi_vel_range_list)),v
s,v
a,v
        print('median of data', np.median(hi_data_sub)),v
